Paxos 算法解决的问题是一个分布式系统如 何就某个值(决议)达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得 到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个"一致性算法"以保证每个节点看到的指令一致。一个通用的一致性算法可 以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的研究就没有停止过。节点通信存在两种模型：共享内存 (Shared memory)和消息传递(Messages passing)。Paxos 算法就是一种基于消息传递模型的一致性算法。

More detailed summary description can be seen in wikipedia.

Two reference for Paxos.
http://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95
http://en.wikipedia.org/wiki/Paxos_algorithm
Paxos算法维基百科，自由的百科全书跳转到: 导航, 搜索

Paxos算法是莱斯利·兰伯特（Leslie Lamport，就是 LaTeX 中的"La"，此人现在在微软研究院）于1990年提出的一种基于消息传递的一致性算法。[1] 这个算法被认为是类似算法中最有效的。
目录[隐藏]

    1 问题和假设
    2 算法
        2.1 算法的提出与证明
        2.2 算法的内容
            2.2.1 决议的提出与通过
            2.2.2 决议的发布
            2.2.3 Progress 的保证
    3 其他
    4 参考文献

问题和假设

Paxos 算法解决的问题是一个分布式系统如 何就某个值(决议)达成一致。一个典型的场景是，在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得 到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执行一个"一致性算法"以保证每个节点看到的指令一致。一个通用的一致性算法可 以应用在许多场景中，是分布式计算中的重要问题。因此从20世纪80年代起对于一致性算法的研究就没有停止过。节点通信存在两种模型：共享内存 (Shared memory)和消息传递(Messages passing)。Paxos 算法就是一种基于消息传递模型的一致性算法。

为描述 paxos 算法，Lamport 虚拟了一个叫做 Paxos 的希腊城邦，这个岛按照议会民主制的政治模式制订法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员，议长或者传递纸条的服务员 都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。但是这里假设没有拜占庭将军问题（Byzantine failure），即虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息；只要等待足够的时间，消息就会被传到。另外，Paxos 岛上的议员是不会反对其他议员提出的决议的。

对应于分布式系统，议员对应于各个节点，制定的法律对应于系统的状态。各个节点需要进入一个一致的状态，例如在独立Cache的对称多处理器系统中，各个处理器读内存的某个字节时，必须读到同样的一个值，否则系统就违背了一致性的要求。一致性要求对应于法律条文只能有一个版本。议员和服务员的不确定性对应于节点和消息传递通道的不可靠性。

算法
算法的提出与证明
首先将议员的角色分为 proposers，acceptors，和 learners(允许身兼数职)。proposers 提出决议，acceptors 批准决议，learners"学习"决议。划分角色后，就可以更精确的定义问题：
    决议(value)只有在被 proposers 提出后才能批准(未经批准的决议称为"提案(proposal)")；
    在一次 Paxos 算法的执行实例中，只批准一个 Value；
    learners 只能获得被批准(chosen)的 Value。

另外还需要保证 Progress。这一点以后再讨论。
作者通过不断加强上述3个约束(主要是第二个)获得了 Paxos 算法。
批准 value 的过程中，首先 proposers 将 value 发送给 acceptors，之后 acceptors 对 value 进行批准。为了满足只批准一个 value 的约束，要求经"多数派(majority)"批准的 value 成为正式的决议(称为"通过"决议)。这是因为无论是按照人数还是按照权重划分，两组"多数派"至少有一个公共的 acceptor，如果每个 acceptor 只能接受一个 value，约束2就能保证。

于是产生了一个显而易见的新约束：
P1：一个 acceptor 只能批准它接收到的第一个 value。
注意 P1 是不完备的。如果恰好一半 acceptor 批准 value A，另一半批准 value B，那么就无法形成多数派，无法批准任何一个值。

P1 暗示可能存在多个提案。约束2并不要求只通过一个提案。只要提案的 value 是一样的，通过多个提案不违背约束2。通过某种方法可以为每个提案分配一个编号，在提案之间建立一个全序关系，后提出的提案编号大。于是可以产生约束 P2：
P2：一旦一个 value 被通过，那么之后通过的 value 必须和这个 value 一样。

如果 P1 和 P2 都能够保证，那么约束2就能够保证。

对 P2 进行加强：
P2a：一旦一个 value v 被通过，那么之后任何 acceptor 再批准的 value 必须是 v。

由于通信是异步的，P2a 和 P1 会发生冲突。如果一个 value 通过后，一个 proposer 和一个 acceptor 从休眠中苏醒，前者提出一个新的 value，根据 P1，后者应当批准；根据 P2a，则不应当批准。于是需要对 proposer 的行为进行约束：
P2b：一旦一个 value v 被通过，那么以后 proposer 提出的新提案必须具有 value v。

P2b 蕴涵了 P2a，是一个更强的约束。

但是根据 P2b 难以提出实现手段。因此需要进一步加强 P2b。

假设一个编号为 m 的 value v 已经获得通过，来看看在什么情况下对任何编号为 n(n>m) 的提案都含有 value v。因为 m 已经获得通过，显然存在一个 acceptors 的多数派 C，他们都批准了 v。根据 P2b，所有编号 m..(n-1) 的提案都具有 value v。考虑到任何多数派都和 C 具有至少一个公共成员，可以找到一个蕴涵 P2b 的约束 P2c：
P2c：如果一个编号为 n 的提案具有 value v，那么存在一个多数派，要么他们中没有人批准过编号小于 n
的任何提案，要么他们进行的最近一次批准具有 value v。

可以用数学归纳法证 明 P2c 蕴涵 P2b：假设具有 value v 的提案 m 获得通过，当 n=m+1 时，根据 P2c，由于任何一个多数派中至少有一个批准了 m，因此提案具有 value v；若 (m+1)..(n-1) 所有提案都具有 value v，根据 P2c，若反设新提案 n 不具有 value v 则存在一个多数派，他们没有批准过 m..(n-1) 中的任何提案。但是我们知道，他们中至少有一个人批准了 m。于是我们导出了矛盾，获得了证明。

P2c 是可以通过消息传递模型实现的。另外，引入了 P2c 后，解决了前文提到的 P1 不完备的问题。

算法的内容

要满足 P2c 的约束，proposer 提出一个提案前，首先要和足以形成多数派的 acceptors 进行通信，获得他们进行的最近一次批准活动的编号(prepare 过程)，之后根据回收的信息决定这次提案的 value，形成提案开始投票。当获得多数 acceptors 批准后，提案获得通过，由 proposer 将这个消息告知 learner。这个简略的过程经过进一步细化后就形成了 Paxos 算法。

每个提案需要有不同的编号，且编号间要存在偏序关系。可以用多种方法实现这一点，例如将序数和 proposer 的名字拼接起来。如何做到这一点不在 Paxos 算法讨论的范围之内。

如果一个 acceptor 在 prepare 过程中回答了一个 proposer 针对"草案" n 的问题，但是在开始对 n 进行投票前，又批准另一个提案(例如 n-1)，如果两个提案具有不同的 value，这个投票就会违背 P2c。因此在 prepare 过程中，acceptor 进行的回答同时也应包含承诺：不会再批准编号小于 n 的提案。这是对 P1 的加强：
P1a：当且仅当 acceptor 没有收到编号大于 n 的 prepare 请求时，acceptor 批准编号为 n 的提案。

现在已经可以提出完整的算法了。

决议的提出与通过

通过一个决议分为两个阶段：

    prepare 阶段：
        proposer 选择一个提案编号 n 并将 prepare 请求发送给 acceptors 中的一个多数派；
        acceptor 收到 prepare 消息后，如果提案的编号大于它已经回复的所有 prepare 消息，则 acceptor 将自己上次的批准回复给 proposer，并承诺不再批准小于 n 的提案；
    批准阶段：
        当一个 proposor 收到了多数 acceptors 对 prepare 的回复后，就进入批准阶段。它要向回复 prepare 请求的 acceptors 发送 accept 请求，包括编号 n 和根据 P2c 决定的 value(如果根据 P2c 没有决定 value，那么它可以自由决定 value)。
        在不违背自己向其他 proposer 的承诺的前提下，acceptor 收到 accept 请求后即批准这个请求。

这个过程在任何时候中断都可以保证正确性。例如如果一个 proposer 发现已经有其他 proposers 提出了编号更高的提案，则有必要中断这个过程。因此为了优化，在上述 prepare 过程中，如果一个 acceptor 发现存在一个更高编号的"草案"，则需要通知 proposer，提醒其中断这次提案。

决议的发布

一个显而易见的方法是当 acceptors 批准一个 value 时，将这个消息发送给所有 learner。但是这个方法会导致消息量过大。
由于假设没有 Byzantine failures，learners 可以通过别的 learners 获取已经通过的决议。因此 acceptors 只需将批准的消息发送给指定的某一个 learner，其他 learners 向它询问已经通过的决议。这个方法降低了消息量，但是指定 learner 失效将引起系统失效。

因此 acceptors 需要将 accept 消息发送给 learners 的一个子集，然后由这些 learners 去通知所有 learners。
但是由于消息传递的不确定性，可能会没有任何 learner 获得了决议批准的消息。当 learners 需要了解决议通过情况时，可以让一个 proposer 重新进行一次提案。注意一个 learner 可能兼任 proposer。

Progress 的保证
根据上述过程当一个 proposer 发现存在编号更大的提案时将终止提案。这意味这提出一个编号更大的提案会终止之前的提案过程。如果两个 proposer 在这种情况下都转而提出一个编号更大的提案，就可能陷入活锁，违背了 Progress 的要求。这种情况下的解决方案是选举出一个 president，仅允许 president 提出提案。但是由于消息传递的不确定性，可能有多个 proposer 自认为自己已经成为 president。Lamport 在The Part-Time Parliament一文中描述并解决了这个问题。

其他
微软公司为简化的 Paxos 算法申请了专利[2]。但专利中公开的技术和本文所描述的不尽相同。

谷歌公司(Google 公司)在其分布式锁服务(Chubby lock)中应用了Paxos算法[3]。Chubby lock 应用于大表(Bigtable)，后者在谷歌公司所提供的各项服务中得到了广泛的应用[4]。

[编辑] 参考文献

    The Part-Time Parliament ── Lamport 于1998年发表在 ACM Transactions on Computer Systems。

    註：这是该算法第一次公开发表。

    Paxos Made Simple，2001年。

    註：Lamport 觉得同行无法接受他的幽默感，于是用容易接受的方法重新表述了一遍。

    Pinewiki对Paxos算法的介绍

    ^ Lamport 本人在 http://research.microsoft.com/users/lamport/pubs/pubs.html#lamport-paxos 中描写了他用9年时间发表这个算法的前前后后
    ^ 中国专利局的相关页面
    ^ The Chubby lock service for loosely-coupled distributed systems
    ^ Bigtable: A Distributed Storage System for Structured Data
来自“http://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95” 
